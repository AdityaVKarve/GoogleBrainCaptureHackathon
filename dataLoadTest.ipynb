{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****Sample Notebook to get started with the EEG dataset****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import mne\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import configparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the dataset class\n",
    "class BhutanDataSet():\n",
    "    \"\"\"\n",
    "    Defines the BhutanDataSet class. This class is used to load the Bhutan EEG dataset and preprocess it for\n",
    "    later use in the BENDR feature representation generation. It is loaded as a raw .edf file and the preprocessed \n",
    "    according to Makoto's pipeline.\n",
    "    \"\"\"\n",
    "    def __init__(self, path, subject, session, event, event_id, tmin, tmax, baseline, filter):\n",
    "        \"\"\"\n",
    "        Initializes the BhutanDataSet class.\n",
    "\n",
    "        Args:\n",
    "            path (str): The path to the raw .edf file.\n",
    "            subject (int): The subject number.\n",
    "            session (int): The session number.\n",
    "            event (str): The event to be extracted.\n",
    "            event_id (int): The event id.\n",
    "            tmin (float): The minimum time to be extracted.\n",
    "            tmax (float): The maximum time to be extracted.\n",
    "            baseline (tuple): The baseline to be used.\n",
    "            filter (tuple): The filter to be used.\n",
    "\n",
    "        \"\"\"\n",
    "        self.path = path\n",
    "        self.subject = subject\n",
    "        self.session = session\n",
    "        self.event = event\n",
    "        self.event_id = event_id\n",
    "        self.tmin = tmin\n",
    "        self.tmax = tmax\n",
    "        self.baseline = baseline\n",
    "        self.filter = filter\n",
    "\n",
    "        print(\"Loading the Bhutan EEG dataset for subject {} and session {}...\".format(self.subject, self.session))\n",
    "\n",
    "        self.raw, self.epochs, self.X, self.y = self.call()\n",
    "\n",
    "    def call(self):\n",
    "        \"\"\"\n",
    "        Calls the BhutanDataSet class.\n",
    "\n",
    "        Returns:\n",
    "            raw (mne.io.edf.edf.RawEDF): The raw .edf file.\n",
    "            epochs (mne.epochs): The preprocessed epochs.\n",
    "            X (np.array): The data.\n",
    "            y (np.array): The labels.\n",
    "\n",
    "        \"\"\"\n",
    "        raw = self.load_data()\n",
    "        # self.visualise_data(raw)\n",
    "        epochs = self.preprocess_data(raw)\n",
    "        X, y = self.extract_data(epochs)\n",
    "        return raw, epochs, X, y\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"\n",
    "        Loads the raw .edf file.\n",
    "\n",
    "        Returns:\n",
    "            raw (mne.io.edf.edf.RawEDF): The raw .edf file.\n",
    "\n",
    "        \"\"\"\n",
    "        raw = mne.io.read_raw_edf(self.path, infer_types=True, verbose=True)\n",
    "        # Print the number of channels and the channel names\n",
    "        print(\"The number of channels is: \", len(raw.info['ch_names']))\n",
    "        print(\"The channel names are: \", raw.info['ch_names'])\n",
    "        raw.drop_channels(['R1', 'R2', 'TIP', 'GROUND', 'REF']) # BAD PRACTICE - REMOVE\n",
    "        return raw\n",
    "    \n",
    "    def visualise_data(self, raw):\n",
    "        \"\"\"\n",
    "        Visualises the raw .edf file.\n",
    "\n",
    "        Args:\n",
    "            raw (mne.io.edf.edf.RawEDF): The raw .edf file.\n",
    "\n",
    "        \"\"\"\n",
    "        raw.plot()\n",
    "    \n",
    "    def preprocess_data(self, raw):\n",
    "        \"\"\"\n",
    "        Preprocesses the raw .edf file.\n",
    "\n",
    "        Args:\n",
    "            raw (mne.io.edf.edf.RawEDF): The raw .edf file.\n",
    "\n",
    "        Returns:\n",
    "            epochs (mne.epochs): The preprocessed epochs.\n",
    "\n",
    "        \"\"\"\n",
    "        # Set the montage\n",
    "        montage = mne.channels.make_standard_montage('standard_1020')\n",
    "        # for montage in mne.channels.get_builtin_montages():\n",
    "        #     try:\n",
    "        #         raw.set_montage(montage, match_case=False)\n",
    "        #         print('Set montage to', montage)\n",
    "        #         break\n",
    "        #     except Exception as e:\n",
    "        #         print(e, 'for', montage)\n",
    "        raw.set_montage(montage, match_case=False)\n",
    "        # Load data into memory\n",
    "        raw.load_data()\n",
    "        # Filter the data\n",
    "        raw.filter(self.filter[0], self.filter[1], fir_design='firwin')\n",
    "        # Extract events\n",
    "        events, event_id = mne.events_from_annotations(raw)\n",
    "        # Extract epochs\n",
    "        # epochs = mne.Epochs(raw, events, event_id, tmin=self.tmin, tmax=self.tmax, baseline=self.baseline, preload=True)\n",
    "        epochs = mne.Epochs(raw, events, baseline=self.baseline, preload=True)\n",
    "        return epochs\n",
    "    \n",
    "    def extract_data(self, epochs):\n",
    "        \"\"\"\n",
    "        Extracts the data from the epochs.\n",
    "\n",
    "        Args:\n",
    "            epochs (mne.epochs): The preprocessed epochs.\n",
    "\n",
    "        Returns:\n",
    "            X (np.array): The data.\n",
    "            y (np.array): The labels.\n",
    "\n",
    "        \"\"\"\n",
    "        X = epochs.get_data()\n",
    "        y = epochs.events[:, -1]\n",
    "        return X, y\n",
    "    \n",
    "class MMIDBDataSet():\n",
    "    \"\"\"\n",
    "    Defines the MMIDBDataSet class. This class is used to load the MMIDB EEG dataset and preprocess it for\n",
    "    later use in the BENDR feature representation generation. It is loaded as a raw .edf file and the preprocessed \n",
    "    according to Makoto's pipeline.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, path, subject, session, event, event_id, tmin, tmax, baseline, filter):\n",
    "        \"\"\"\n",
    "        Initializes the MMIDBDataSet class.\n",
    "\n",
    "        Args:\n",
    "            path (str): The path to the raw .edf file.\n",
    "            subject (int): The subject number.\n",
    "            session (int): The session number.\n",
    "            event (str): The event to be extracted.\n",
    "            event_id (int): The event id.\n",
    "            tmin (float): The minimum time to be extracted.\n",
    "            tmax (float): The maximum time to be extracted.\n",
    "            baseline (tuple): The baseline to be used.\n",
    "            filter (tuple): The filter to be used.\n",
    "\n",
    "        \"\"\"\n",
    "        self.path = path\n",
    "        self.subject = subject\n",
    "        self.session = session\n",
    "        self.event = event\n",
    "        self.event_id = event_id\n",
    "        self.tmin = tmin\n",
    "        self.tmax = tmax\n",
    "        self.baseline = baseline\n",
    "        self.filter = filter\n",
    "\n",
    "        print(\"Loading the MMIDB EEG dataset for subject {} and session {}...\".format(self.subject, self.session))\n",
    "\n",
    "        self.raw, self.epochs, self.X, self.y = self.call()\n",
    "\n",
    "    def call(self):\n",
    "        \"\"\"\n",
    "        Calls the MMIDBDataSet class.\n",
    "\n",
    "        Returns:\n",
    "            raw (mne.io.edf.edf.RawEDF): The raw .edf file.\n",
    "            epochs (mne.epochs): The preprocessed epochs.\n",
    "            X (np.array): The data.\n",
    "            y (np.array): The labels.\n",
    "\n",
    "        \"\"\"\n",
    "        raw = self.load_data()\n",
    "        # self.visualise_data(raw)\n",
    "        epochs = self.preprocess_data(raw)\n",
    "        X, y = self.extract_data(epochs)\n",
    "        return raw, epochs, X, y\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"\n",
    "        Loads the raw .edf file.\n",
    "\n",
    "        Returns:\n",
    "            raw (mne.io.edf.edf.RawEDF): The raw .edf file.\n",
    "\n",
    "        \"\"\"\n",
    "        raw = mne.io.read_raw_edf(self.path, infer_types=True, verbose=True)\n",
    "        # Print the number of channels and the channel names\n",
    "        print(\"The number of channels is: \", len(raw.info['ch_names']))\n",
    "        print(\"The channel names are: \", raw.info['ch_names'])\n",
    "\n",
    "        # Rename channelse, remove all .'s and spaces\n",
    "        raw.rename_channels(lambda x: x.strip('.').replace(' ', ''))\n",
    "        return raw\n",
    "    \n",
    "    def visualise_data(self, raw):\n",
    "        \"\"\"\n",
    "        Visualises the raw .edf file.\n",
    "\n",
    "        Args:\n",
    "            raw (mne.io.edf.edf.RawEDF): The raw .edf file.\n",
    "\n",
    "        \"\"\"\n",
    "        raw.plot()\n",
    "\n",
    "    def preprocess_data(self, raw):\n",
    "        \"\"\"\n",
    "        Preprocesses the raw .edf file.\n",
    "\n",
    "        Args:\n",
    "            raw (mne.io.edf.edf.RawEDF): The raw .edf file.\n",
    "\n",
    "        Returns:\n",
    "            epochs (mne.epochs): The preprocessed epochs.\n",
    "\n",
    "        \"\"\"\n",
    "        # Set the montage\n",
    "        montage = mne.channels.make_standard_montage('standard_1020')\n",
    "        raw.set_montage(montage, match_case=False)\n",
    "        # Load data into memory\n",
    "        raw.load_data()\n",
    "        # Filter the data\n",
    "        raw.filter(self.filter[0], self.filter[1], fir_design='firwin')\n",
    "        # Extract events\n",
    "        events, event_id = mne.events_from_annotations(raw)\n",
    "        # Extract epochs\n",
    "        epochs = mne.Epochs(raw, events, event_id, tmin=self.tmin, tmax=self.tmax, baseline=self.baseline, preload=True)\n",
    "        return epochs\n",
    "    \n",
    "    def extract_data(self, epochs):\n",
    "        \"\"\"\n",
    "        Extracts the data from the epochs.\n",
    "\n",
    "        Args:\n",
    "            epochs (mne.epochs): The preprocessed epochs.\n",
    "\n",
    "        Returns:\n",
    "            X (np.array): The data.\n",
    "            y (np.array): The labels.\n",
    "\n",
    "        \"\"\"\n",
    "        X = epochs.get_data()\n",
    "        y = epochs.events[:, -1]\n",
    "        return X, y\n",
    "    \n",
    "\n",
    "    \n",
    "def load_config(path='config.ini'):\n",
    "    \"\"\"\n",
    "    Loads the configuration file.\n",
    "\n",
    "    Returns:\n",
    "        config (configparser.ConfigParser): The configuration file.\n",
    "\n",
    "    \"\"\"\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read(path)\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the configuration file\n",
    "config = load_config()\n",
    "\n",
    "# Load the Bhutan EEG dataset\n",
    "bhutan = BhutanDataSet('data/Bhutan_Data/test_file.edf', subject=int(config['Bhutan']['subject']), \n",
    "                        session=int(config['Bhutan']['session']), event=config['Bhutan']['event'], \n",
    "                        event_id=int(config['Bhutan']['event_id']), tmin=int(config['Bhutan']['tmin']), \n",
    "                        tmax=int(config['Bhutan']['tmax']), baseline=None, \n",
    "                        filter=(float(config['Bhutan']['filter1']), float(config['Bhutan']['filter2'])))\n",
    "\n",
    "# investigate x and y\n",
    "print(bhutan.X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the configuration file\n",
    "config = load_config()\n",
    "\n",
    "# Load the MMIDB EEG dataset\n",
    "mmidb = MMIDBDataSet('data/MMIDB/S013R01.edf', subject=int(config['MMIDB']['subject']), \n",
    "                        session=int(config['MMIDB']['session']), event=config['MMIDB']['event'], \n",
    "                        event_id=int(config['MMIDB']['event_id']), tmin=int(config['MMIDB']['tmin']), \n",
    "                        tmax=int(config['MMIDB']['tmax']), baseline=None, \n",
    "                        filter=(float(config['MMIDB']['filter1']), float(config['MMIDB']['filter2'])))\n",
    "\n",
    "# investigate x and y\n",
    "print(mmidb.X.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
