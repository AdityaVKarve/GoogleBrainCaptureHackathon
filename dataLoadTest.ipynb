{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****Sample Notebook to get started with the EEG dataset****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/benjaminfazal/anaconda3/envs/DTU_1/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (1.23.5)\n",
      "Requirement already satisfied: matplotlib in /Users/benjaminfazal/anaconda3/envs/DTU_1/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (3.8.0)\n",
      "Requirement already satisfied: sympy<1.10 in /Users/benjaminfazal/anaconda3/envs/DTU_1/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (1.9)\n",
      "Requirement already satisfied: tqdm in /Users/benjaminfazal/anaconda3/envs/DTU_1/lib/python3.11/site-packages (from -r requirements.txt (line 4)) (4.65.0)\n",
      "Requirement already satisfied: seaborn in /Users/benjaminfazal/anaconda3/envs/DTU_1/lib/python3.11/site-packages (from -r requirements.txt (line 5)) (0.13.2)\n",
      "Requirement already satisfied: scikit-learn in /Users/benjaminfazal/anaconda3/envs/DTU_1/lib/python3.11/site-packages (from -r requirements.txt (line 6)) (1.3.2)\n",
      "Requirement already satisfied: pandas in /Users/benjaminfazal/anaconda3/envs/DTU_1/lib/python3.11/site-packages (from -r requirements.txt (line 7)) (2.1.1)\n",
      "Requirement already satisfied: mne in /Users/benjaminfazal/anaconda3/envs/DTU_1/lib/python3.11/site-packages (from -r requirements.txt (line 8)) (1.6.1)\n",
      "Requirement already satisfied: torch in /Users/benjaminfazal/anaconda3/envs/DTU_1/lib/python3.11/site-packages (from -r requirements.txt (line 9)) (2.1.2)\n",
      "Requirement already satisfied: tabulate in /Users/benjaminfazal/anaconda3/envs/DTU_1/lib/python3.11/site-packages (from -r requirements.txt (line 10)) (0.9.0)\n",
      "Requirement already satisfied: scipy in /Users/benjaminfazal/anaconda3/envs/DTU_1/lib/python3.11/site-packages (from -r requirements.txt (line 11)) (1.11.4)\n",
      "Requirement already satisfied: braindecode in /Users/benjaminfazal/anaconda3/envs/DTU_1/lib/python3.11/site-packages (from -r requirements.txt (line 12)) (0.8.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/benjaminfazal/anaconda3/envs/DTU_1/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 2)) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/benjaminfazal/anaconda3/envs/DTU_1/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 2)) (0.12.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/benjaminfazal/anaconda3/envs/DTU_1/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 2)) (4.43.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/benjaminfazal/anaconda3/envs/DTU_1/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 2)) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/benjaminfazal/anaconda3/envs/DTU_1/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 2)) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/benjaminfazal/anaconda3/envs/DTU_1/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 2)) (10.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/benjaminfazal/anaconda3/envs/DTU_1/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 2)) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/benjaminfazal/anaconda3/envs/DTU_1/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 2)) (2.8.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/benjaminfazal/anaconda3/envs/DTU_1/lib/python3.11/site-packages (from sympy<1.10->-r requirements.txt (line 3)) (1.3.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/benjaminfazal/anaconda3/envs/DTU_1/lib/python3.11/site-packages (from scikit-learn->-r requirements.txt (line 6)) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/benjaminfazal/anaconda3/envs/DTU_1/lib/python3.11/site-packages (from scikit-learn->-r requirements.txt (line 6)) (2.2.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/benjaminfazal/anaconda3/envs/DTU_1/lib/python3.11/site-packages (from pandas->-r requirements.txt (line 7)) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/benjaminfazal/anaconda3/envs/DTU_1/lib/python3.11/site-packages (from pandas->-r requirements.txt (line 7)) (2023.3)\n",
      "Requirement already satisfied: pooch>=1.5 in /Users/benjaminfazal/anaconda3/envs/DTU_1/lib/python3.11/site-packages (from mne->-r requirements.txt (line 8)) (1.8.0)\n",
      "Requirement already satisfied: decorator in /Users/benjaminfazal/anaconda3/envs/DTU_1/lib/python3.11/site-packages (from mne->-r requirements.txt (line 8)) (5.1.1)\n",
      "Requirement already satisfied: jinja2 in /Users/benjaminfazal/anaconda3/envs/DTU_1/lib/python3.11/site-packages (from mne->-r requirements.txt (line 8)) (3.1.2)\n",
      "Requirement already satisfied: lazy-loader>=0.3 in /Users/benjaminfazal/anaconda3/envs/DTU_1/lib/python3.11/site-packages (from mne->-r requirements.txt (line 8)) (0.3)\n",
      "Requirement already satisfied: filelock in /Users/benjaminfazal/anaconda3/envs/DTU_1/lib/python3.11/site-packages (from torch->-r requirements.txt (line 9)) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/benjaminfazal/anaconda3/envs/DTU_1/lib/python3.11/site-packages (from torch->-r requirements.txt (line 9)) (4.7.1)\n",
      "Requirement already satisfied: networkx in /Users/benjaminfazal/anaconda3/envs/DTU_1/lib/python3.11/site-packages (from torch->-r requirements.txt (line 9)) (3.2.1)\n",
      "Requirement already satisfied: fsspec in /Users/benjaminfazal/anaconda3/envs/DTU_1/lib/python3.11/site-packages (from torch->-r requirements.txt (line 9)) (2023.12.2)\n",
      "Requirement already satisfied: h5py in /Users/benjaminfazal/anaconda3/envs/DTU_1/lib/python3.11/site-packages (from braindecode->-r requirements.txt (line 12)) (3.9.0)\n",
      "Requirement already satisfied: skorch in /Users/benjaminfazal/anaconda3/envs/DTU_1/lib/python3.11/site-packages (from braindecode->-r requirements.txt (line 12)) (0.15.0)\n",
      "Requirement already satisfied: einops in /Users/benjaminfazal/anaconda3/envs/DTU_1/lib/python3.11/site-packages (from braindecode->-r requirements.txt (line 12)) (0.7.0)\n",
      "Requirement already satisfied: torchinfo in /Users/benjaminfazal/anaconda3/envs/DTU_1/lib/python3.11/site-packages (from braindecode->-r requirements.txt (line 12)) (1.8.0)\n",
      "Requirement already satisfied: docstring-inheritance in /Users/benjaminfazal/anaconda3/envs/DTU_1/lib/python3.11/site-packages (from braindecode->-r requirements.txt (line 12)) (2.1.2)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /Users/benjaminfazal/anaconda3/envs/DTU_1/lib/python3.11/site-packages (from pooch>=1.5->mne->-r requirements.txt (line 8)) (3.10.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/benjaminfazal/anaconda3/envs/DTU_1/lib/python3.11/site-packages (from pooch>=1.5->mne->-r requirements.txt (line 8)) (2.31.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/benjaminfazal/anaconda3/envs/DTU_1/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib->-r requirements.txt (line 2)) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/benjaminfazal/anaconda3/envs/DTU_1/lib/python3.11/site-packages (from jinja2->mne->-r requirements.txt (line 8)) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/benjaminfazal/anaconda3/envs/DTU_1/lib/python3.11/site-packages (from requests>=2.19.0->pooch>=1.5->mne->-r requirements.txt (line 8)) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/benjaminfazal/anaconda3/envs/DTU_1/lib/python3.11/site-packages (from requests>=2.19.0->pooch>=1.5->mne->-r requirements.txt (line 8)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/benjaminfazal/anaconda3/envs/DTU_1/lib/python3.11/site-packages (from requests>=2.19.0->pooch>=1.5->mne->-r requirements.txt (line 8)) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/benjaminfazal/anaconda3/envs/DTU_1/lib/python3.11/site-packages (from requests>=2.19.0->pooch>=1.5->mne->-r requirements.txt (line 8)) (2023.11.17)\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import mne\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import configparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the dataset class\n",
    "class BhutanDataSet():\n",
    "    \"\"\"\n",
    "    Defines the BhutanDataSet class. This class is used to load the Bhutan EEG dataset and preprocess it for\n",
    "    later use in the BENDR feature representation generation. It is loaded as a raw .edf file and the preprocessed \n",
    "    according to Makoto's pipeline.\n",
    "    \"\"\"\n",
    "    def __init__(self, path, subject, session, event, event_id, tmin, tmax, baseline, filter):\n",
    "        \"\"\"\n",
    "        Initializes the BhutanDataSet class.\n",
    "\n",
    "        Args:\n",
    "            path (str): The path to the raw .edf file.\n",
    "            subject (int): The subject number.\n",
    "            session (int): The session number.\n",
    "            event (str): The event to be extracted.\n",
    "            event_id (int): The event id.\n",
    "            tmin (float): The minimum time to be extracted.\n",
    "            tmax (float): The maximum time to be extracted.\n",
    "            baseline (tuple): The baseline to be used.\n",
    "            filter (tuple): The filter to be used.\n",
    "\n",
    "        \"\"\"\n",
    "        self.path = path\n",
    "        self.subject = subject\n",
    "        self.session = session\n",
    "        self.event = event\n",
    "        self.event_id = event_id\n",
    "        self.tmin = tmin\n",
    "        self.tmax = tmax\n",
    "        self.baseline = baseline\n",
    "        self.filter = filter\n",
    "\n",
    "        print(\"Loading the Bhutan EEG dataset for subject {} and session {}...\".format(self.subject, self.session))\n",
    "\n",
    "        self.raw, self.epochs, self.X, self.y = self.call()\n",
    "\n",
    "    def call(self):\n",
    "        \"\"\"\n",
    "        Calls the BhutanDataSet class.\n",
    "\n",
    "        Returns:\n",
    "            raw (mne.io.edf.edf.RawEDF): The raw .edf file.\n",
    "            epochs (mne.epochs): The preprocessed epochs.\n",
    "            X (np.array): The data.\n",
    "            y (np.array): The labels.\n",
    "\n",
    "        \"\"\"\n",
    "        raw = self.load_data()\n",
    "        # self.visualise_data(raw)\n",
    "        epochs = self.preprocess_data(raw)\n",
    "        X, y = self.extract_data(epochs)\n",
    "        return raw, epochs, X, y\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"\n",
    "        Loads the raw .edf file.\n",
    "\n",
    "        Returns:\n",
    "            raw (mne.io.edf.edf.RawEDF): The raw .edf file.\n",
    "\n",
    "        \"\"\"\n",
    "        raw = mne.io.read_raw_edf(self.path, infer_types=True, verbose=True)\n",
    "        # Print the number of channels and the channel names\n",
    "        print(\"The number of channels is: \", len(raw.info['ch_names']))\n",
    "        print(\"The channel names are: \", raw.info['ch_names'])\n",
    "        raw.drop_channels(['R1', 'R2', 'TIP', 'GROUND', 'REF']) # BAD PRACTICE - REMOVE\n",
    "        return raw\n",
    "    \n",
    "    def visualise_data(self, raw):\n",
    "        \"\"\"\n",
    "        Visualises the raw .edf file.\n",
    "\n",
    "        Args:\n",
    "            raw (mne.io.edf.edf.RawEDF): The raw .edf file.\n",
    "\n",
    "        \"\"\"\n",
    "        raw.plot()\n",
    "    \n",
    "    def preprocess_data(self, raw):\n",
    "        \"\"\"\n",
    "        Preprocesses the raw .edf file.\n",
    "\n",
    "        Args:\n",
    "            raw (mne.io.edf.edf.RawEDF): The raw .edf file.\n",
    "\n",
    "        Returns:\n",
    "            epochs (mne.epochs): The preprocessed epochs.\n",
    "\n",
    "        \"\"\"\n",
    "        # Set the montage\n",
    "        montage = mne.channels.make_standard_montage('standard_1020')\n",
    "        # for montage in mne.channels.get_builtin_montages():\n",
    "        #     try:\n",
    "        #         raw.set_montage(montage, match_case=False)\n",
    "        #         print('Set montage to', montage)\n",
    "        #         break\n",
    "        #     except Exception as e:\n",
    "        #         print(e, 'for', montage)\n",
    "        raw.set_montage(montage, match_case=False)\n",
    "        # Load data into memory\n",
    "        raw.load_data()\n",
    "        # Filter the data\n",
    "        raw.filter(self.filter[0], self.filter[1], fir_design='firwin')\n",
    "        # Extract events\n",
    "        events, event_id = mne.events_from_annotations(raw)\n",
    "        # Extract epochs\n",
    "        # epochs = mne.Epochs(raw, events, event_id, tmin=self.tmin, tmax=self.tmax, baseline=self.baseline, preload=True)\n",
    "        epochs = mne.Epochs(raw, events, baseline=self.baseline, preload=True)\n",
    "        return epochs\n",
    "    \n",
    "    def extract_data(self, epochs):\n",
    "        \"\"\"\n",
    "        Extracts the data from the epochs.\n",
    "\n",
    "        Args:\n",
    "            epochs (mne.epochs): The preprocessed epochs.\n",
    "\n",
    "        Returns:\n",
    "            X (np.array): The data.\n",
    "            y (np.array): The labels.\n",
    "\n",
    "        \"\"\"\n",
    "        X = epochs.get_data()\n",
    "        y = epochs.events[:, -1]\n",
    "        return X, y\n",
    "    \n",
    "class MMIDBDataSet():\n",
    "    \"\"\"\n",
    "    Defines the MMIDBDataSet class. This class is used to load the MMIDB EEG dataset and preprocess it for\n",
    "    later use in the BENDR feature representation generation. It is loaded as a raw .edf file and the preprocessed \n",
    "    according to Makoto's pipeline.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, path, subject, session, event, event_id, tmin, tmax, baseline, filter):\n",
    "        \"\"\"\n",
    "        Initializes the MMIDBDataSet class.\n",
    "\n",
    "        Args:\n",
    "            path (str): The path to the raw .edf file.\n",
    "            subject (int): The subject number.\n",
    "            session (int): The session number.\n",
    "            event (str): The event to be extracted.\n",
    "            event_id (int): The event id.\n",
    "            tmin (float): The minimum time to be extracted.\n",
    "            tmax (float): The maximum time to be extracted.\n",
    "            baseline (tuple): The baseline to be used.\n",
    "            filter (tuple): The filter to be used.\n",
    "\n",
    "        \"\"\"\n",
    "        self.path = path\n",
    "        self.subject = subject\n",
    "        self.session = session\n",
    "        self.event = event\n",
    "        self.event_id = event_id\n",
    "        self.tmin = tmin\n",
    "        self.tmax = tmax\n",
    "        self.baseline = baseline\n",
    "        self.filter = filter\n",
    "\n",
    "        print(\"Loading the MMIDB EEG dataset for subject {} and session {}...\".format(self.subject, self.session))\n",
    "\n",
    "        self.raw, self.epochs, self.X, self.y = self.call()\n",
    "\n",
    "    def call(self):\n",
    "        \"\"\"\n",
    "        Calls the MMIDBDataSet class.\n",
    "\n",
    "        Returns:\n",
    "            raw (mne.io.edf.edf.RawEDF): The raw .edf file.\n",
    "            epochs (mne.epochs): The preprocessed epochs.\n",
    "            X (np.array): The data.\n",
    "            y (np.array): The labels.\n",
    "\n",
    "        \"\"\"\n",
    "        raw = self.load_data()\n",
    "        # self.visualise_data(raw)\n",
    "        epochs = self.preprocess_data(raw)\n",
    "        X, y = self.extract_data(epochs)\n",
    "        return raw, epochs, X, y\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"\n",
    "        Loads the raw .edf file.\n",
    "\n",
    "        Returns:\n",
    "            raw (mne.io.edf.edf.RawEDF): The raw .edf file.\n",
    "\n",
    "        \"\"\"\n",
    "        raw = mne.io.read_raw_edf(self.path, infer_types=True, verbose=True)\n",
    "        # Print the number of channels and the channel names\n",
    "        print(\"The number of channels is: \", len(raw.info['ch_names']))\n",
    "        print(\"The channel names are: \", raw.info['ch_names'])\n",
    "\n",
    "        # Rename channelse, remove all .'s and spaces\n",
    "        raw.rename_channels(lambda x: x.strip('.').replace(' ', ''))\n",
    "        return raw\n",
    "    \n",
    "    def visualise_data(self, raw):\n",
    "        \"\"\"\n",
    "        Visualises the raw .edf file.\n",
    "\n",
    "        Args:\n",
    "            raw (mne.io.edf.edf.RawEDF): The raw .edf file.\n",
    "\n",
    "        \"\"\"\n",
    "        raw.plot()\n",
    "\n",
    "    def preprocess_data(self, raw):\n",
    "        \"\"\"\n",
    "        Preprocesses the raw .edf file.\n",
    "\n",
    "        Args:\n",
    "            raw (mne.io.edf.edf.RawEDF): The raw .edf file.\n",
    "\n",
    "        Returns:\n",
    "            epochs (mne.epochs): The preprocessed epochs.\n",
    "\n",
    "        \"\"\"\n",
    "        # Set the montage\n",
    "        montage = mne.channels.make_standard_montage('standard_1020')\n",
    "        raw.set_montage(montage, match_case=False)\n",
    "        # Load data into memory\n",
    "        raw.load_data()\n",
    "        # Filter the data\n",
    "        raw.filter(self.filter[0], self.filter[1], fir_design='firwin')\n",
    "        # Extract events\n",
    "        events, event_id = mne.events_from_annotations(raw)\n",
    "        # Extract epochs\n",
    "        epochs = mne.Epochs(raw, events, event_id, tmin=self.tmin, tmax=self.tmax, baseline=self.baseline, preload=True)\n",
    "        return epochs\n",
    "    \n",
    "    def extract_data(self, epochs):\n",
    "        \"\"\"\n",
    "        Extracts the data from the epochs.\n",
    "\n",
    "        Args:\n",
    "            epochs (mne.epochs): The preprocessed epochs.\n",
    "\n",
    "        Returns:\n",
    "            X (np.array): The data.\n",
    "            y (np.array): The labels.\n",
    "\n",
    "        \"\"\"\n",
    "        X = epochs.get_data()\n",
    "        y = epochs.events[:, -1]\n",
    "        return X, y\n",
    "    \n",
    "\n",
    "    \n",
    "def load_config(path='config.ini'):\n",
    "    \"\"\"\n",
    "    Loads the configuration file.\n",
    "\n",
    "    Returns:\n",
    "        config (configparser.ConfigParser): The configuration file.\n",
    "\n",
    "    \"\"\"\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read(path)\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the Bhutan EEG dataset for subject 1 and session 1...\n",
      "Extracting EDF parameters from /Users/benjaminfazal/Downloads/Bhutan Data/test_file.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "The number of channels is:  32\n",
      "The channel names are:  ['FP1', 'FP2', 'F3', 'F4', 'C3', 'C4', 'P3', 'P4', 'O1', 'O2', 'F7', 'F8', 'T7', 'T8', 'TP7', 'TP8', 'P7', 'P8', 'F9', 'F10', 'T9', 'T10', 'P9', 'P10', 'Fz', 'Cz', 'Pz', 'R1', 'R2', 'TIP', 'GROUND', 'REF']\n",
      "Reading 0 ... 686591  =      0.000 ...  2681.996 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.5 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.50\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 1691 samples (6.605 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['Eye blinking', 'Eye movement left-right', 'Eyes closed', 'Hyperventilation', 'Jaw clenching']\n",
      "Not setting metadata\n",
      "5 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 5 events and 180 original time points ...\n",
      "0 bad epochs dropped\n",
      "(5, 27, 180)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:    0.2s finished\n",
      "/var/folders/s7/nyq_w8f57z1f7styfc9q4k600000gn/T/ipykernel_59142/3760430642.py:124: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  X = epochs.get_data()\n"
     ]
    }
   ],
   "source": [
    "# Load the configuration file\n",
    "config = load_config()\n",
    "\n",
    "# Load the Bhutan EEG dataset\n",
    "bhutan = BhutanDataSet('/Users/benjaminfazal/Downloads/Bhutan Data/test_file.edf', subject=int(config['Bhutan']['subject']), \n",
    "                        session=int(config['Bhutan']['session']), event=config['Bhutan']['event'], \n",
    "                        event_id=int(config['Bhutan']['event_id']), tmin=int(config['Bhutan']['tmin']), \n",
    "                        tmax=int(config['Bhutan']['tmax']), baseline=None, \n",
    "                        filter=(float(config['Bhutan']['filter1']), float(config['Bhutan']['filter2'])))\n",
    "\n",
    "# investigate x and y\n",
    "print(bhutan.X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the MMIDB EEG dataset for subject 1 and session 1...\n",
      "Extracting EDF parameters from /Users/benjaminfazal/Downloads/MMIDB/S013R01.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "The number of channels is:  64\n",
      "The channel names are:  ['Fc5.', 'Fc3.', 'Fc1.', 'Fcz.', 'Fc2.', 'Fc4.', 'Fc6.', 'C5..', 'C3..', 'C1..', 'Cz..', 'C2..', 'C4..', 'C6..', 'Cp5.', 'Cp3.', 'Cp1.', 'Cpz.', 'Cp2.', 'Cp4.', 'Cp6.', 'Fp1.', 'Fpz.', 'Fp2.', 'Af7.', 'Af3.', 'Afz.', 'Af4.', 'Af8.', 'F7..', 'F5..', 'F3..', 'F1..', 'Fz..', 'F2..', 'F4..', 'F6..', 'F8..', 'Ft7.', 'Ft8.', 'T7..', 'T8..', 'T9..', 'T10.', 'Tp7.', 'Tp8.', 'P7..', 'P5..', 'P3..', 'P1..', 'Pz..', 'P2..', 'P4..', 'P6..', 'P8..', 'Po7.', 'Po3.', 'Poz.', 'Po4.', 'Po8.', 'O1..', 'Oz..', 'O2..', 'Iz..']\n",
      "Reading 0 ... 9759  =      0.000 ...    60.994 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.5 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.50\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 1057 samples (6.606 s)\n",
      "\n",
      "Used Annotations descriptions: ['T0']\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 9601 original time points ...\n",
      "0 bad epochs dropped\n",
      "(1, 64, 9601)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  64 out of  64 | elapsed:    0.0s finished\n",
      "/var/folders/s7/nyq_w8f57z1f7styfc9q4k600000gn/T/ipykernel_59142/3760430642.py:245: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  X = epochs.get_data()\n"
     ]
    }
   ],
   "source": [
    "# Load the configuration file\n",
    "config = load_config()\n",
    "\n",
    "# Load the MMIDB EEG dataset\n",
    "mmidb = MMIDBDataSet('/Users/benjaminfazal/Downloads/MMIDB/S013R01.edf', subject=int(config['MMIDB']['subject']), \n",
    "                        session=int(config['MMIDB']['session']), event=config['MMIDB']['event'], \n",
    "                        event_id=int(config['MMIDB']['event_id']), tmin=int(config['MMIDB']['tmin']), \n",
    "                        tmax=int(config['MMIDB']['tmax']), baseline=None, \n",
    "                        filter=(float(config['MMIDB']['filter1']), float(config['MMIDB']['filter2'])))\n",
    "\n",
    "# investigate x and y\n",
    "print(mmidb.X.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
