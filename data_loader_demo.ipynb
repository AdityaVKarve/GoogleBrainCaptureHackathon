{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mne\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.data.utils.eeg import get_raw\n",
    "from src.data.processing import load_data_dict, get_data\n",
    "from src.data.conf.eeg_annotations import tuh_eeg_artefact_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = r'C:/Users/wille/OneDrive - Danmarks Tekniske Universitet/Dokumenter/0. Thesis/trustworthy-causal-ai/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Suppress logger messages from MNE-Python\n",
    "mne_logger = logging.getLogger('mne')\n",
    "mne_logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TUAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuar_hackathon_path = data_folder + 'hackathon 01/TUAR/01_tcp_ar/'\n",
    "\n",
    "tuar_folders = os.listdir(tuar_hackathon_path)\n",
    "len(tuar_folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "    <tr>\n",
       "        <th>Measurement date</th>\n",
       "        \n",
       "        <td>November 15, 2010  09:11:06 GMT</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Experimenter</th>\n",
       "        \n",
       "        <td>Unknown</td>\n",
       "        \n",
       "    </tr>\n",
       "        <th>Participant</th>\n",
       "        \n",
       "            \n",
       "            <td>aaaaaaju</td>\n",
       "            \n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Digitized points</th>\n",
       "        \n",
       "        <td>22 points</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Good channels</th>\n",
       "        <td>19 EEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Bad channels</th>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>EOG channels</th>\n",
       "        <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>ECG channels</th>\n",
       "        <td>Not available</td>\n",
       "    \n",
       "    <tr>\n",
       "        <th>Sampling frequency</th>\n",
       "        <td>256.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Highpass</th>\n",
       "        <td>1.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Lowpass</th>\n",
       "        <td>70.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Filenames</th>\n",
       "        <td>S001R05_t000.edf</td>\n",
       "    </tr>\n",
       "    \n",
       "    <tr>\n",
       "        <th>Duration</th>\n",
       "        <td>00:24:02 (HH:MM:SS)</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<RawEDF | S001R05_t000.edf, 19 x 369152 (1442.0 s), ~53.5 MB, data loaded>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject = 'S001'\n",
    "session = 'R05'\n",
    "token = 't000'\n",
    "\n",
    "example_file = tuar_hackathon_path + f'{subject}/{subject}{session}_{token}.edf'\n",
    "\n",
    "raw = get_raw(example_file)\n",
    "raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'scale' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data_dict \u001b[38;5;241m=\u001b[39m \u001b[43mload_data_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_folder_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtuar_hackathon_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mannotation_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtuh_eeg_artefact_annotations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtlen\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\wille\\OneDrive - Danmarks Tekniske Universitet\\Dokumenter\\0. Thesis\\GoogleBrainCaptureHackathon\\src\\data\\processing.py:92\u001b[0m, in \u001b[0;36mload_data_dict\u001b[1;34m(data_folder_path, annotation_dict, tmin, tlen, labels)\u001b[0m\n\u001b[0;32m     89\u001b[0m             epochs \u001b[38;5;241m=\u001b[39m mne\u001b[38;5;241m.\u001b[39mmake_fixed_length_epochs(raw, duration\u001b[38;5;241m=\u001b[39mtlen, preload\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     91\u001b[0m         X \u001b[38;5;241m=\u001b[39m epochs\u001b[38;5;241m.\u001b[39mget_data()\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m---> 92\u001b[0m         X \u001b[38;5;241m=\u001b[39m \u001b[43mnormalize_and_add_scaling_channel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m         data_dict[subject][session_name][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m X\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data_dict\n",
      "File \u001b[1;32mc:\\Users\\wille\\OneDrive - Danmarks Tekniske Universitet\\Dokumenter\\0. Thesis\\GoogleBrainCaptureHackathon\\src\\data\\processing.py:34\u001b[0m, in \u001b[0;36mnormalize_and_add_scaling_channel\u001b[1;34m(x, low, high, data_min, data_max, scale_idx)\u001b[0m\n\u001b[0;32m     30\u001b[0m X[:, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m     32\u001b[0m max_scale \u001b[38;5;241m=\u001b[39m data_max \u001b[38;5;241m-\u001b[39m data_min\n\u001b[1;32m---> 34\u001b[0m scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m (torch\u001b[38;5;241m.\u001b[39mclamp_max((xmin \u001b[38;5;241m-\u001b[39m xmax) \u001b[38;5;241m/\u001b[39m max_scale, \u001b[38;5;241m1.0\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(\u001b[43mscale\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m, scale\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(scale\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(X\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: cannot access local variable 'scale' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "data_dict = load_data_dict(data_folder_path=tuar_hackathon_path, annotation_dict=tuh_eeg_artefact_annotations, tmin=-0.5, tlen=5, labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_subjects = list(data_dict.keys())\n",
    "\n",
    "percentage = 0.5\n",
    "some_subjects = np.random.choice(all_subjects, int(len(all_subjects) * percentage), replace=False)\n",
    "\n",
    "X, y = get_data(data_dict, some_subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5]),\n",
       " array([5605,  254, 4962, 3493,   14,    2], dtype=int64))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MMIDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuar_hackathon_path = data_folder + 'raw/MMIDB/files/'\n",
    "\n",
    "tuar_folders = os.listdir(tuar_hackathon_path)\n",
    "len(tuar_folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hackathon' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m session \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mR03\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      4\u001b[0m example_file \u001b[38;5;241m=\u001b[39m tuar_hackathon_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msubject\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msubject\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msession\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtoken\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.edf\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 6\u001b[0m raw \u001b[38;5;241m=\u001b[39m get_raw(example_file, \u001b[43mhackathon\u001b[49m, standard_19_channel)\n\u001b[0;32m      7\u001b[0m raw\n",
      "\u001b[1;31mNameError\u001b[0m: name 'hackathon' is not defined"
     ]
    }
   ],
   "source": [
    "subject = 'S001'\n",
    "session = 'R03'\n",
    "\n",
    "example_file = tuar_hackathon_path + f'{subject}/{subject}{session}_{token}.edf'\n",
    "\n",
    "raw = get_raw(example_file, hackathon, standard_19_channel)\n",
    "raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "braincapture",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
